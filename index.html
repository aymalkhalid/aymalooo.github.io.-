<!DOCTYPE html>
<html>
<head>
    <title>Home</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    <script src="https://cdn.jsdelivr.net/npm/elevenlabs-js@latest/dist/elevenlabs.min.js"></script>
</head>
<body>
   <!-- Add this right after the opening <body> tag -->
  <div id="modal-overlay" class="modal-overlay">
    <div class="modal-content">
      <h2>Welcome to DISH Agent</h2>
      <p>Please enter your information to continue</p>
      
      <form id="user-info-form">
        <div class="form-group">
          <label for="firstName">Applicant Name</label>
          <input type="text" id="firstName" name="firstName" required>
        </div>
        
        <div class="form-group">
          <label for="position">Applicant Position</label>
          <input type="text" id="position" name="position" required>
        </div>
        
        <div class="form-group">
          <label for="lastJob">Last Job Company</label>
          <input type="text" id="lastJob" name="lastJob" required>
        </div>
        <!--  -->
        <div class="form-group">
          <label for="elevenLabsKey">ElevenLabs API Key</label>
          <input type="password" id="elevenLabsKey" required>
          <small>Get your key at <a href="https://elevenlabs.io/app" target="_blank">elevenlabs.io</a></small>
        </div>

        <button type="submit" class="submit-btn">Start Conversation</button>
      </form>
    </div>
  </div>
   <!--End of Popup  -->
    <link rel="stylesheet" href="https://www.gstatic.com/dialogflow-console/fast/df-messenger/prod/v1/themes/df-messenger-default.css">
    <script src="https://www.gstatic.com/dialogflow-console/fast/df-messenger/prod/v1/df-messenger.js"></script>
    <df-messenger
      project-id="agent-demos-v1"
      agent-id="fa47c7e0-4ea7-431d-ba0f-a62126f4070a"
      language-code="en"
      max-query-length="-1"
      allow-feedback="all"
      intent="WELCOME"
      >
      <df-messenger-chat
       chat-title="Hybrid DISH Agent"
       >
      </df-messenger-chat>
    </df-messenger>
    <button id="start-voice-input" class="voice-button">
      <i class="fas fa-microphone"></i>
    </button>
    <div id="speech-status" style="position: fixed; bottom: 115px; right: 20px; color: #007bff; font-weight: bold; background-color: rgba(255,255,255,0.8); padding: 5px 10px; border-radius: 5px; display: none;"></div>
    <div id="transcription-display" style="position: fixed; bottom: 100px; left: 20px; color: #333; font-weight: bold; background-color: rgba(255,255,255,0.95); padding: 12px 15px; border-radius: 8px; max-width: 80%; width: 400px; text-align: left; box-shadow: 0 4px 12px rgba(0,0,0,0.15); border-left: 4px solid #007bff; z-index: 1100; display: none; transition: all 0.3s ease;"></div>
    <div id="error-message" style="position: fixed; bottom: 85px; right: 20px; color: red;"></div>
    <style>
      df-messenger {
        z-index: 999;
        position: fixed;
        --df-messenger-font-color: #000;
        --df-messenger-font-family: Google Sans;
        --df-messenger-chat-background: #f3f6fc;
        --df-messenger-message-user-background: #d3e3fd;
        --df-messenger-message-bot-background: #fff;
        top: 0;
        right: 0;
        bottom: 0;
        left: 0;
        width: 80%;
        height: 100%;
      }
      .voice-button {
        position: fixed;
        bottom: 20px;
        right: 20px;
        background-color: #007bff;
        color: white;
        border: none;
        border-radius: 50%;
        width: 60px;
        height: 60px;
        display: flex;
        align-items: center;
        justify-content: center;
        font-size: 24px;
        cursor: pointer;
        transition: background-color 0.3s;
      }
      .voice-button:focus {
        outline: none;
      }
      .voice-button.listening {
        background-color: #ff0000;
        animation: pulse-animation 1s infinite;
      }
      .pulse {
        animation: pulse-animation 2s infinite;
      }
      @keyframes pulse-animation {
        0% {
          transform: scale(1);
        }
        50% {
          transform: scale(1.2);
        }
        100% {
          transform: scale(1);
        }
      }
      .feedback-wrapper {
        display: grid;
        grid-template-columns: repeat(auto-fill, minmax(200px, 1fr));
        gap: 10px;
      }
      .feedback-wrapper label {
        display: flex;
        align-items: center;
      }
      .feedback-wrapper input[type="checkbox"] {
        margin-right: 10px;
      }
      .feedback-wrapper button {
        background-color: #007bff;
        color: white;
        border: none;
        padding: 10px 20px;
        border-radius: 5px;
        cursor: pointer;
        font-size: 16px;
        margin-top: 10px;
      }
      .feedback-wrapper button:hover {
        background-color: #0056b3;
      }
      .feedback-wrapper button:focus {
        outline: none;
      }
      .feedback-wrapper textarea {
        width: 100%;
        height: 100px;
        padding: 10px;
        border: 1px solid #ccc;
        border-radius: 5px;
        font-size: 16px;
        resize: vertical;
      }
      .feedback-wrapper textarea:focus {
        border-color: #007bff;
        outline: none;
      }
      #speech-status {
        transition: opacity 0.3s ease;
        opacity: 0.9;
        box-shadow: 0 2px 5px rgba(0,0,0,0.1);
      }
      @keyframes blink {
        0%, 100% { opacity: 1; }
        50% { opacity: 0.5; }
      }
      #speech-status.listening {
        animation: blink 1.5s infinite;
      }
      .modal-overlay {
        position: fixed;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        background-color: rgba(0, 0, 0, 0.7);
        display: flex;
        justify-content: center;
        align-items: center;
        z-index: 1000;
      }
      .modal-content {
        background-color: white;
        padding: 30px;
        border-radius: 10px;
        max-width: 500px;
        width: 90%;
        box-shadow: 0 5px 15px rgba(0, 0, 0, 0.3);
      }
      .modal-content h2 {
        margin-top: 0;
        color: #007bff;
      }
      .form-group {
        margin-bottom: 20px;
      }
      .form-group label {
        display: block;
        margin-bottom: 5px;
        font-weight: bold;
      }
      .form-group input {
        width: 100%;
        padding: 10px;
        border: 1px solid #ddd;
        border-radius: 5px;
        font-size: 16px;
      }
      .submit-btn {
        background-color: #007bff;
        color: white;
        border: none;
        padding: 12px 20px;
        border-radius: 5px;
        font-size: 16px;
        cursor: pointer;
        width: 100%;
      }
      .submit-btn:hover {
        background-color: #0056b3;
      }
      .voice-button.ready-to-send {
        box-shadow: 0 0 15px rgba(255, 0, 0, 0.7);
        transform: scale(1.1);
      }
    </style>
<!--  -->
  <script>
    document.addEventListener('DOMContentLoaded', function() {
      // Apply blur to background elements
      const dfMessenger = document.querySelector('df-messenger');
      const voiceButton = document.getElementById('start-voice-input');
      
      dfMessenger.classList.add('blur-background');
      voiceButton.classList.add('blur-background');
      
      // Handle form submission
      const userInfoForm = document.getElementById('user-info-form');
      userInfoForm.addEventListener('submit', function(event) {
        event.preventDefault();
        
        // Get form values
        const firstName = document.getElementById('firstName').value.trim();
        const position = document.getElementById('position').value.trim();
        const lastJob = document.getElementById('lastJob').value.trim();
        
        // Validate inputs
        if (!firstName || !position || !lastJob) {
          alert('Please fill in all fields');
          return;
        }
        
        // Store values in global variables to be used by setUserInformation
        window.userInfo = {
          firstName: firstName,
          position: position,
          lastJob: lastJob
        };
        
        // Remove blur effect
        dfMessenger.classList.remove('blur-background');
        voiceButton.classList.remove('blur-background');
        
        // Hide modal
        document.getElementById('modal-overlay').style.display = 'none';
        
        // Initialize the chatbot with user info
        initializeAgent();
      });
    });
    
    function initializeAgent() {
      setUserInformation();
    }
  </script>
<!-- //  -->
<script>
  const startVoiceInputButton = document.getElementById('start-voice-input');
  const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
  recognition.lang = 'en-US';
  recognition.interimResults = false;
  recognition.maxAlternatives = 1;
  recognition.continuous = true;
  
  let isRecognitionActive = false;
  let currentTranscript = '';
  let allTranscripts = [];
  let speechWasInterrupted = false;
  
  function showListeningStatus(isListening) {
    const speechStatus = document.getElementById('speech-status');
    if (isListening) {
      speechStatus.textContent = "Listening...";
      speechStatus.style.display = "block";
      speechStatus.classList.add('listening');
    } else {
      speechStatus.style.display = "none";
      speechStatus.classList.remove('listening');
    }
  }
  
  startVoiceInputButton.addEventListener('click', () => {
    if (!isRecognitionActive) {
    // Add this at the beginning of the if block
    if (audioElement) {
      audioElement.pause();
      audioElement = null;
      console.log('ElevenLabs audio playback interrupted');
    }
    
    // Existing code continues...
    if (window.speechSynthesis.speaking) {
      speechWasInterrupted = true;
      console.log('Speech interrupted by user');
    }
    window.speechSynthesis.cancel();
      if (window.speechSynthesis.speaking) {
        speechWasInterrupted = true;
        console.log('Speech interrupted by user');
      }
      window.speechSynthesis.cancel();
      
      currentTranscript = '';
      allTranscripts = [];
      startVoiceInputButton.innerHTML = '<i class="fas fa-stop"></i>';
      startVoiceInputButton.classList.add('listening');
      startVoiceInputButton.setAttribute('title', 'Click to stop and send transcript');
      recognition.start();
      isRecognitionActive = true;
      showListeningStatus(true);
      
      // const transcriptionDisplay = document.getElementById('transcription-display');
      // transcriptionDisplay.innerHTML = '<i class="fas fa-comment-dots" style="margin-right: 8px; color: #007bff;"></i> <span style="color: #007bff;">Listening for speech...</span>';
      // transcriptionDisplay.style.display = 'block';
    } else {
      recognition.stop();
      isRecognitionActive = false;
      startVoiceInputButton.innerHTML = '<i class="fas fa-microphone"></i>';
      startVoiceInputButton.classList.remove('listening', 'ready-to-send');
      startVoiceInputButton.setAttribute('title', 'Click to start speaking');
      showListeningStatus(false);
      console.log('Stop requested');
    }
  });

  // This function finalizes transcript in the end event
  recognition.addEventListener('end', () => {
    if (!isRecognitionActive) {
      // The user pressed stop, so finalize & send
      console.log("Transcript segments before sending:", JSON.stringify(allTranscripts));
      let fullTranscript = allTranscripts.length ? allTranscripts.join(' ').trim() : '';
      console.log("Combined transcript to send:", fullTranscript);
      
      const transcriptionDisplay = document.getElementById('transcription-display');
      if (fullTranscript) {
        // transcriptionDisplay.innerHTML = `<i class="fas fa-paper-plane" style="margin-right: 8px; color: #28a745;"></i>
        //   <span style="color: #28a745;">Sending:</span> 
        //   <span style="font-weight: normal;">${fullTranscript}</span>`;
        // transcriptionDisplay.style.display = 'block';
        
        const dfMessenger = document.querySelector('df-messenger');
        try {
          dfMessenger.renderCustomText(fullTranscript, false);
          setTimeout(() => {
            dfMessenger.sendRequest('query', fullTranscript);
            console.log("✅ Transcript successfully sent to Dialogflow");
          }, 100);
        } catch (error) {
          console.error("Error sending transcript:", error);
        }
        
        setTimeout(() => {
          transcriptionDisplay.style.display = 'none';
        }, 1500);
      } else {
        console.log("⚠️ No transcript content to send");
        transcriptionDisplay.style.display = 'block';
        transcriptionDisplay.innerHTML = `<i class="fas fa-exclamation-triangle" style="margin-right: 8px; color: #ffc107;"></i>
          <span style="color: #ffc107;">No speech detected.</span>`;
        setTimeout(() => {
          transcriptionDisplay.style.display = 'none';
        }, 2000);
      }
      currentTranscript = '';
      allTranscripts = [];
    } else {
      // If still active, user wants continuous listening
      setTimeout(() => {
        try {
          recognition.start();
          console.log('Speech recognition restarted');
        } catch (error) {
          console.error('Error restarting speech recognition:', error);
          isRecognitionActive = false;
          startVoiceInputButton.innerHTML = '<i class="fas fa-microphone"></i>';
          startVoiceInputButton.classList.remove('listening');
          showListeningStatus(false);
        }
      }, 10);
    }
  });

  recognition.addEventListener('result', (event) => {
    console.log("Speech recognition result:", event.results);
    
    const latestTranscript = event.results[event.results.length - 1][0].transcript;
    currentTranscript = latestTranscript;
    allTranscripts.push(latestTranscript);
    console.log("Current transcript segments:", allTranscripts);
    
    const transcriptionDisplay = document.getElementById('transcription-display');
    // transcriptionDisplay.innerHTML = `
    //   <i class="fas fa-comment-dots" style="margin-right: 8px; color: #007bff;"></i> 
    //   <span style="color: #007bff;">Transcribing:</span> 
    //   <span style="font-weight: normal;">${latestTranscript}</span>
    //   <div style="margin-top: 8px; font-size: 12px; color: #666; text-align: right;">
    //     <i class="fas fa-info-circle"></i> Click <i class="fas fa-stop" style="color: #ff0000;"></i> to send
    //   </div>
    // `;
    // transcriptionDisplay.style.display = 'block';
    startVoiceInputButton.classList.add('ready-to-send');
  });

  recognition.addEventListener('error', (event) => {
    console.error('Speech recognition error detected: ' + event.error);
    const errorMessage = document.getElementById('error-message');
    
    switch (event.error) {
      case 'no-speech':
        errorMessage.textContent = 'No speech detected.';
        break;
      case 'audio-capture':
        errorMessage.textContent = 'Microphone access denied or not available.';
        stopRecognition();
        break;
      case 'not-allowed':
        errorMessage.textContent = 'Permission to use the microphone was denied.';
        stopRecognition();
        break;
      default:
        errorMessage.textContent = 'An error occurred during speech recognition.';
        if (event.error !== 'aborted') {
          stopRecognition();
        }
    }
    
    // Clear error message after a timeout
    if (event.error) {
      setTimeout(() => {
        if (!errorMessage.textContent.startsWith('Transcribing:')) {
          errorMessage.textContent = '';
          errorMessage.style.color = 'red'; 
        }
      }, 3000);
    }
  });
  
  function stopRecognition() {
    isRecognitionActive = false;
    startVoiceInputButton.innerHTML = '<i class="fas fa-microphone"></i>';
    startVoiceInputButton.classList.remove('listening');
    showListeningStatus(false);
    currentTranscript = '';
    allTranscripts = [];
  }
</script>
<!--  -->

<!--  -->
<script>
  /**
   * @fileoverview DISH Agent Dialogflow Integration Script
   * 
   * This script manages the integration between the web interface and Dialogflow CX,
   * handling speech synthesis, voice feedback, user information management, and 
   * custom feedback collection for the DISH Networks agent interview simulation.
   * 
   * @version 1.0.0
   * @author DISH Networks Team
   * 
   * ===== GLOBAL VARIABLES =====
   * 
   * @var {Array} speechSynthesisVoices - Stores available speech synthesis voices
   * @var {boolean} voicesLoaded - Flag indicating if voices have been loaded
   * @var {boolean} isFirstResponse - Flag for special handling of first AI response
   * @var {number} FlagWelcome - Tracks welcome message state (0: not sent, 1: preparing, 2: sent)
   * @var {string} AIMessage - Stores the most recent AI response text
   * @var {Array} feedbackTextsList - Collects all feedback texts submitted by users
   * @var {Array} selectedOptionsList - Collects all feedback options selected by users
   * 
   * ===== MAIN COMPONENTS =====
   * 
   * 1. CUSTOM FEEDBACK ELEMENT
   *    - Creates a custom web component for collecting user feedback
   *    - Renders checkboxes for quick feedback options and text area for detailed comments
   *    - Dispatches custom events when feedback is submitted
   * 
   * 2. SPEECH SYNTHESIS MANAGEMENT
   *    - Loads and manages available speech synthesis voices
   *    - Handles text-to-speech conversion for AI responses
   *    - Manages speaking status indicators
   * 
   * 3. DIALOGFLOW INTEGRATION
   *    - Listens for responses from Dialogflow Messenger
   *    - Processes and speaks AI responses
   *    - Handles user information for personalized interactions
   * 
   * 4. PARAMETER MANAGEMENT
   *    - Sets query parameters for Dialogflow with user information
   *    - Passes feedback data to Dialogflow for analytics
   * 
   * ===== DETAILED WORKFLOW =====
   * 
   * 1. On page load:
   *    - Attempts to load speech synthesis voices
   *    - Sets up event listeners for voice changes
   * 
   * 2. When user submits the welcome form:
   *    - User information is stored and passed to Dialogflow
   *    - Welcome message is triggered
   * 
   * 3. When Dialogflow responds:
   *    - Response text is captured and spoken aloud
   *    - First response gets special handling (delayed speaking if needed)
   * 
   * 4. When user provides feedback:
   *    - Feedback text and selected options are stored
   *    - Data is passed to Dialogflow via query parameters
   * 
   * ===== FUNCTION REFERENCE =====
   */
  

  let speechSynthesisVoices = [];
  let voicesLoaded = false;
  let isFirstResponse = true;
  let FlagWelcome = 0;
  let AIMessage = '';
  // Global arrays to store feedback text and selected options
  const feedbackTextsList = [];
  const selectedOptionsList = [];
  const feedbackAITextList = [];
  /**
   * @class CustomFeedbackElement
   * @extends HTMLElement
   * @description Custom web component that creates a feedback interface with checkboxes and text input
   */    
  class CustomFeedbackElement extends HTMLElement {
    constructor() {
      super();
      this.renderRoot = this.attachShadow({ mode: 'open' });
    }
/**
 * @method connectedCallback
 * @description Lifecycle method that runs when the element is added to the DOM
 * Renders the feedback interface with checkboxes and text area, and adds a submit button.
 * Dispatches a custom event with feedback data when the submit button is clicked. 
 */
    connectedCallback() {
      const wrapper = document.createElement('div');
      wrapper.classList.add('feedback-wrapper');

      const options = [
        "Inaccurate", "Partially Accurate", "Unhelpful", "Context Lost", 
        "Unnatural Language", "Repetitive", "Edge Case Failure", "Human Escalation Needed"
      ];

      options.forEach(option => {
        const label = document.createElement('label');
        const checkbox = document.createElement('input');
        checkbox.type = 'checkbox';
        checkbox.value = option;
        label.appendChild(checkbox);
        label.appendChild(document.createTextNode(option));
        wrapper.appendChild(label);
      });

      wrapper.appendChild(document.createElement('br'));
      wrapper.appendChild(document.createElement('br'));
      const textArea = document.createElement('textarea');
      
      textArea.placeholder = 'Enter your feedback here...';
      textArea.style.width = '100%';
      textArea.style.height = '100px';
      textArea.id = 'feedback-text';
      wrapper.appendChild(textArea);

      const button = document.createElement('button');
      button.innerText = 'Submit';
      button.addEventListener('click', () => {
        this._onSubmitClick();
      });
      wrapper.appendChild(button);

      this.renderRoot.appendChild(wrapper);
    }

    _onSubmitClick() {
      const feedbackText = this.renderRoot.getElementById('feedback-text').value;
      const checkboxes = this.renderRoot.querySelectorAll('input[type="checkbox"]');
      const selectedOptions = Array.from(checkboxes)
        .filter(checkbox => checkbox.checked)
        .map(checkbox => checkbox.value);
      
      feedbackTextsList.push(feedbackText);
      selectedOptionsList.push(selectedOptions);
      feedbackAITextList.push(AIMessage)
      // Dispatch custom event with feedback data
      const event = new CustomEvent("df-custom-submit-feedback-clicked", {
        detail: JSON.stringify({
          "feedback": feedbackTextsList,
          "selectedOptions": selectedOptionsList,
          "feedbackAITextList": feedbackAITextList
        }),
        bubbles: true,
        composed: true,
      });
      this.dispatchEvent(event);
    }
  }
/**
 * @function funsetQueryParameters
 * @description Sets query parameters for Dialogflow with feedback data
 * @param {Array} feedbackTextsList - List of feedback text submitted by users
 * 
 */ 
  (function() {customElements.define('df-external-custom-feedback', CustomFeedbackElement);})();

  document.addEventListener('df-custom-submit-feedback-clicked', (event) => {
    console.log('Feedback submitted:', event.detail); 
    const submitted_feedback = JSON.parse(event.detail);
    funsetQueryParameters(submitted_feedback.feedback, submitted_feedback.selectedOptions, submitted_feedback.feedbackAITextList);
  });   
/**
 * @function loadVoices
 * @description Loads available speech synthesis voices and sets the global voicesLoaded flag
 * @returns {boolean} - Flag indicating if voices have been loaded
 * 
 */ 
  function loadVoices() {
    console.log('Loading voices...');
    speechSynthesisVoices = window.speechSynthesis.getVoices();
    voicesLoaded = speechSynthesisVoices.length > 0;
    console.log(`${speechSynthesisVoices.length} voices loaded, voicesLoaded=${voicesLoaded}`);
    return voicesLoaded;
  }
  // 
  loadVoices();
/**
 * @function showSpeechStatus
 * @description Displays the speaking status indicator
 * @param {boolean} isSpeaking - Flag indicating if speech synthesis is active
 */
  if (window.speechSynthesis.onvoiceschanged !== undefined) {
    window.speechSynthesis.onvoiceschanged = function() {
      voicesLoaded = loadVoices();
      console.log('Voices changed event triggered');
    };
  }
/**
 * @function showSpeechStatus
 * @description Displays the speaking status indicator
 * @param {boolean} isSpeaking - Flag indicating if speech synthesis is active
 */
  function showSpeechStatus(isSpeaking) {
    const speechStatus = document.getElementById('speech-status');
    if (isSpeaking) {
      speechStatus.textContent = "Speaking...";
      speechStatus.style.display = "block";
    } else {
      speechStatus.style.display = "none";
    }
  }

// Add these global variables at the top of your script section with other globals
// Remove these lines
let audioElement = null;
const ELEVEN_LABS_API_KEY = document.getElementById('elevenLabsKey').value; // API Key for ElevenLabs
console.log('ElevenLabs API Key:', ELEVEN_LABS_API_KEY);
const VOICE_ID = 'kdmDKE6EkgrWrrykO9Qt'; // Voice ID for ElevenLabs API

// Get the current API key from the input field
function getElevenLabsApiKey() {
  console.log('Getting ElevenLabs API Key:', document.getElementById('elevenLabsKey').value);
  return document.getElementById('elevenLabsKey').value;
}

/**
 * @function speakText
 * @description Converts text to speech using ElevenLabs API
 * @param {string} text - Text to be spoken
 */
async function speakText(text) {
  if (!text || typeof text !== 'string') {
    console.log('Invalid text to speak:', text);
    return;
  }
  
  console.log('Speaking with ElevenLabs:', text);
  
  // Stop any current playback
  if (audioElement) {
    audioElement.pause();
    audioElement = null;
  }
  
  // Show speaking status
  showSpeechStatus(true);
  
  try {
    // Call ElevenLabs API
    const response = await fetch(`https://api.elevenlabs.io/v1/text-to-speech/${VOICE_ID}`, {
      method: 'POST',
      headers: {
        'Accept': 'audio/mpeg',
        'Content-Type': 'application/json',
        'xi-api-key': getElevenLabsApiKey() 
      },
      body: JSON.stringify({
        text: text,
        model_id: 'eleven_monolingual_v1',
        voice_settings: {
          stability: 0.5,
          similarity_boost: 0.5
        }
      })
    });
    
    if (!response.ok) {
      throw new Error(`ElevenLabs API error: ${response.status}`);
    }
    
    // Get audio blob from response
    const audioBlob = await response.blob();
    const audioUrl = URL.createObjectURL(audioBlob);
    
    // Play the audio
    audioElement = new Audio(audioUrl);
    
    audioElement.onended = () => {
      console.log('Finished speaking');
      showSpeechStatus(false);
      URL.revokeObjectURL(audioUrl);
    };
    
    audioElement.onerror = (err) => {
      console.error('Audio playback error:', err);
      showSpeechStatus(false);
      URL.revokeObjectURL(audioUrl);
    };
    
    await audioElement.play();
    
  } catch (error) {
    console.error('ElevenLabs TTS error:', error);
    showSpeechStatus(false);
    
    // Fallback to browser's speech synthesis if ElevenLabs fails
    const utterance = new SpeechSynthesisUtterance(text);
    utterance.lang = 'en-US';
    utterance.rate = 1.0;
    utterance.pitch = 1.2;
    window.speechSynthesis.speak(utterance);
  }
}
/**
 * Listen to Dialogflow response events and process AI messages, with special handling for the first response. 
 */  
  const dfMessenger = document.querySelector('df-messenger');
  dfMessenger.addEventListener('df-response-received', (event) => {
      console.log(`Response received (isFirstResponse=${isFirstResponse}):`, 
        event.detail.raw.queryResult.diagnosticInfo);
      
      const responseData = event.detail;
      if (responseData.messages && responseData.messages.length > 0) {
        console.log('Message:', responseData.messages[0].text);
        AIMessage = responseData.messages[0].text;
        
        if (isFirstResponse) {
          isFirstResponse = false;
          console.log('Processing first response with special handling');
          
          if (!voicesLoaded) {
            loadVoices();
            setTimeout(() => {
              speakText(AIMessage);
            }, 300);
          } else {
            speakText(AIMessage);
          }
        } else {
          speakText(AIMessage);
        }
      }
      
      if (FlagWelcome === 0 && window.userInfo) {
        FlagWelcome = 1;
        setUserInformation();
      }
  });
/**
 * @function setUserInformation
 * @description Sets user information parameters for Dialogflow
 * 
 */  
  function setUserInformation() {
    const dfMessenger = document.querySelector('df-messenger');
    console.log("Setting user parameters");
    
    const userInfo = window.userInfo || {
      firstName: "Jonathan",
      position: "Wireless Customer Service Agent",
      lastJob: "Disney"
    };
    
    const queryParameters = {
      parameters: {
        job_applicant_first_name: userInfo.firstName,
        job_applicant_position: userInfo.position,
        job_applicant_last_Job: userInfo.lastJob,
      }
    };
    
    dfMessenger.setQueryParameters(queryParameters);
    console.log("Parameters set successfully:", userInfo);
    console.log("Flag", FlagWelcome);
    if (FlagWelcome === 0) {
      console.log("Sending welcome message");
      dfMessenger.sendRequest('query', 'Hello');
      FlagWelcome = 2;
    }
  }
/**
 * @function funsetQueryParameters
 * @description Sets query parameters for Dialogflow with feedback data For analytics and Improvements.
 * @param {Array} feedbackTextsList - List of feedback text submitted by users
 * @param {Array} selectedOptionsList - List of feedback options selected by users
 */  
  function funsetQueryParameters(feedbackTextsList, selectedOptionsList) {
    const dfMessenger = document.querySelector('df-messenger');
    const queryParameters = {
      parameters: {
        feedbackTextsList: feedbackTextsList,
        selectedOptionsList: selectedOptionsList,
        feedbackAITextList: feedbackAITextList
      }
    };
    dfMessenger.setQueryParameters(queryParameters);  
    console.log("Set query parameters with feedback and selected options");
    console.log("Feedback Texts List: ", feedbackTextsList);
    console.log("Selected Options List: ", selectedOptionsList);
    console.log("AI Message: ", AIMessage);
  }
</script>
</body>
</html>
